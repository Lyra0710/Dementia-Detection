{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the CDR - The Clinical Dementia Rating. Higher the number, higher the chances of dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"OASIS4_data_CDR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your plotting code here\n",
    "\n",
    "plt.show()  # Display the plot in the Jupyter Notebook output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary module\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "# # Create a ProfileReport object\n",
    "# report = ProfileReport(df)\n",
    "\n",
    "# # Generate the data profiling report\n",
    "# report.to_file('oasis_4_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1158, 11)\n"
     ]
    }
   ],
   "source": [
    "#print number of rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values of columns 3 onwards with the mean of the respective columns, excpet column 'cdr'\n",
    "df.iloc[:,2:-1] = df.iloc[:,2:-1].fillna(df.iloc[:,2:-1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oasis_id       0\n",
       "cdr_id         0\n",
       "visit_days     0\n",
       "memory         0\n",
       "orient         0\n",
       "judgement      0\n",
       "community      0\n",
       "homehobb       0\n",
       "perscare       0\n",
       "sumbox         0\n",
       "cdr           10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the null values from 'cdr'\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the columns in df and convert all the int columns to float, except 'cdr'\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'int64':\n",
    "        df[col] = df[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1148 entries, 0 to 1157\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   oasis_id    1148 non-null   object \n",
      " 1   cdr_id      1148 non-null   object \n",
      " 2   visit_days  1148 non-null   float64\n",
      " 3   memory      1148 non-null   float64\n",
      " 4   orient      1148 non-null   float64\n",
      " 5   judgement   1148 non-null   float64\n",
      " 6   community   1148 non-null   float64\n",
      " 7   homehobb    1148 non-null   float64\n",
      " 8   perscare    1148 non-null   float64\n",
      " 9   sumbox      1148 non-null   float64\n",
      " 10  cdr         1148 non-null   float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 107.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['oasis_id', 'cdr_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert contents of 'cdr' column to string\n",
    "df['cdr'] = df['cdr'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1148 entries, 0 to 1157\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   visit_days  1148 non-null   float64\n",
      " 1   memory      1148 non-null   float64\n",
      " 2   orient      1148 non-null   float64\n",
      " 3   judgement   1148 non-null   float64\n",
      " 4   community   1148 non-null   float64\n",
      " 5   homehobb    1148 non-null   float64\n",
      " 6   perscare    1148 non-null   float64\n",
      " 7   sumbox      1148 non-null   float64\n",
      " 8   cdr         1148 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 89.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5    654\n",
      "1.0    294\n",
      "0.0    102\n",
      "2.0     96\n",
      "3.0      2\n",
      "Name: cdr, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print count of each type of values 'cdr'\n",
    "print(df['cdr'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# df['cdr'] = le.fit_transform(df['cdr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.5\n",
      "1       0.5\n",
      "2       0.5\n",
      "3       0.5\n",
      "4       0.5\n",
      "       ... \n",
      "1153    0.5\n",
      "1154    0.5\n",
      "1155    0.5\n",
      "1156    0.5\n",
      "1157    0.5\n",
      "Name: cdr, Length: 1148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['cdr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into x and y where y is 'Group' \n",
    "x = df.drop(columns=['cdr'])\n",
    "y = df['cdr']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standad Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_subset = x_train.iloc[:, 2:]\n",
    "x_train_scaled = scaler.fit_transform(x_train_subset)\n",
    "x_train.iloc[:, 2:] = x_train_scaled\n",
    "\n",
    "x_test_subset = x_test.iloc[:, 2:]\n",
    "x_test_scaled = scaler.transform(x_test_subset)\n",
    "x_test.iloc[:, 2:] = x_test_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Confusion Matrix:\n",
      "[[ 18   3   0   0]\n",
      " [  0 130   0   1]\n",
      " [  0   7  51   1]\n",
      " [  0   2   0  17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression after smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Confusion Matrix:\n",
      "[[112   8   3   0   0]\n",
      " [  7 130  11   0   0]\n",
      " [  0   4 120   9   0]\n",
      " [  0   7   2 119   0]\n",
      " [  0   0   0   0 122]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform SMOTE with reduced k_neighbors\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=1)  # Adjust k_neighbors as needed\n",
    "X_resampled, y_resampled = smote.fit_resample(x, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train_res, x_test, y_train_res, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.03\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create an XGBoost regressor\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate the mean squared error to evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

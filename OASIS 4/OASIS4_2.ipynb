{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"OASIS4_data_clinical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your plotting code here\n",
    "\n",
    "plt.show()  # Display the plot in the Jupyter Notebook output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary module\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "# # Create a ProfileReport object\n",
    "# report = ProfileReport(df)\n",
    "\n",
    "# # Generate the data profiling report\n",
    "# report.to_file('oasis_4_2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('oasis_id' , axis=1,inplace=True)\n",
    "df.drop('demographics_id', axis=1,inplace=True)\n",
    "df.drop('demographics_firstvisit', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 660 entries, 0 to 662\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   sex                   660 non-null    int64  \n",
      " 1   age                   660 non-null    int64  \n",
      " 2   edu                   660 non-null    int64  \n",
      " 3   race                  660 non-null    int64  \n",
      " 4   hispanic              660 non-null    int64  \n",
      " 5   marriage              660 non-null    int64  \n",
      " 6   declong               660 non-null    float64\n",
      " 7   decage                660 non-null    int64  \n",
      " 8   smoke                 660 non-null    int64  \n",
      " 9   height                660 non-null    float64\n",
      " 10  weight                660 non-null    float64\n",
      " 11  bmi                   660 non-null    float64\n",
      " 12  health_history1       660 non-null    int64  \n",
      " 13  health_history2       660 non-null    int64  \n",
      " 14  health_history3       660 non-null    int64  \n",
      " 15  health_history4       660 non-null    int64  \n",
      " 16  health_history5       660 non-null    int64  \n",
      " 17  health_history6       660 non-null    int64  \n",
      " 18  health_history7       660 non-null    int64  \n",
      " 19  health_history10      660 non-null    int64  \n",
      " 20  health_history11      660 non-null    int64  \n",
      " 21  health_history12      660 non-null    int64  \n",
      " 22  final_dx              660 non-null    object \n",
      " 23  final_dx_categorized  660 non-null    int64  \n",
      "dtypes: float64(4), int64(19), object(1)\n",
      "memory usage: 128.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the columns in df and convert all the int columns to float, except 'cdr'\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'int64':\n",
    "        df[col] = df[col].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('hispanic', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 660 entries, 0 to 662\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   sex                   660 non-null    float64\n",
      " 1   age                   660 non-null    float64\n",
      " 2   edu                   660 non-null    float64\n",
      " 3   race                  660 non-null    float64\n",
      " 4   marriage              660 non-null    float64\n",
      " 5   declong               660 non-null    float64\n",
      " 6   decage                660 non-null    float64\n",
      " 7   smoke                 660 non-null    float64\n",
      " 8   height                660 non-null    float64\n",
      " 9   weight                660 non-null    float64\n",
      " 10  bmi                   660 non-null    float64\n",
      " 11  health_history1       660 non-null    float64\n",
      " 12  health_history2       660 non-null    float64\n",
      " 13  health_history3       660 non-null    float64\n",
      " 14  health_history4       660 non-null    float64\n",
      " 15  health_history5       660 non-null    float64\n",
      " 16  health_history6       660 non-null    float64\n",
      " 17  health_history7       660 non-null    float64\n",
      " 18  health_history10      660 non-null    float64\n",
      " 19  health_history11      660 non-null    float64\n",
      " 20  health_history12      660 non-null    float64\n",
      " 21  final_dx              660 non-null    object \n",
      " 22  final_dx_categorized  660 non-null    float64\n",
      "dtypes: float64(22), object(1)\n",
      "memory usage: 123.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('race', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alzheimer Disease Dementia                  219\n",
       "Uncertain - AD possible                     118\n",
       "MCI                                          49\n",
       "Cognitively Normal                           47\n",
       "AD/Vascular                                  40\n",
       "Mood/polypharmacy/sleep                      31\n",
       "Early Onset AD                               27\n",
       "FTD                                          25\n",
       "Non-Neurodegenerative Neurologic Disease     22\n",
       "Vascular Cognitive Impairment (VCI)          16\n",
       "Other - Miscellaneous                        15\n",
       "AD Variant                                   12\n",
       "DLB                                          11\n",
       "Other Non-AD Neurodegenerative Disorder      11\n",
       "AD+Non Neurodegenerative                     10\n",
       "PPA                                           7\n",
       "Name: final_dx, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique values in final_dx\n",
    "df['final_dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode final_dx\n",
    "df.drop('final_dx', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df.drop(['final_dx_categorized'], axis=1)\n",
    "y = df[['final_dx_categorized']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_resampled = scaler.fit_transform(x_train_resampled)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import os\n",
    "# class CSVLogger:\n",
    "#     def __init__(self, filename, fieldnames):\n",
    "#         self.filename = filename\n",
    "#         self.fieldnames = fieldnames\n",
    "\n",
    "#         # Create and initialize the CSV file\n",
    "#         if not os.path.isfile(self.filename):\n",
    "#             with open(self.filename, 'w', newline='') as csvfile:\n",
    "#                 writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "#                 writer.writeheader()\n",
    "#         else:\n",
    "#             with open(self.filename, 'a', newline='') as csvfile:\n",
    "#                 writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "#                 writer.writerow({})\n",
    "\n",
    "#     def log(self, data):\n",
    "#         # Append data to the CSV file\n",
    "#         with open(self.filename, 'a', newline='') as csvfile:\n",
    "#             writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "#             writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a CSVLogger object\n",
    "# csv_logger = CSVLogger( '.csv', ['model', 'accuracy'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 1 0 0 0 0 2 1 0 1 3 1]\n",
      " [0 8 4 0 0 0 1 8 1 5 4 0 1 9 5]\n",
      " [0 0 1 0 1 1 1 1 0 0 0 0 0 1 0]\n",
      " [0 0 2 2 0 0 0 0 1 2 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 0 0 2 1 0]\n",
      " [0 1 0 1 0 1 1 0 0 1 1 2 0 1 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      " [0 3 2 1 0 0 0 2 0 0 1 0 0 1 1]\n",
      " [1 2 1 2 0 1 2 2 2 3 0 1 2 0 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# log = {'model': 'Logistic Regression with SMOTE', 'accuracy': accuracy}\n",
    "# csv_logger.log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # svm\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Perform SMOTE with reduced k_neighbors\n",
    "# smote = SMOTE(sampling_strategy='auto', k_neighbors=1)  # Adjust k_neighbors as needed\n",
    "# x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# # Train the model\n",
    "# model = SVC(kernel='linear', random_state=42)\n",
    "# model.fit(x_resampled, y_resampled)\n",
    "\n",
    "# # Make predictions and evaluate\n",
    "# predictions = model.predict(x_test)\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# conf_matrix = confusion_matrix(y_test, predictions)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # log = {'model': 'SVM with SMOTE', 'accuracy': accuracy}\n",
    "# # csv_logger.log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# log = {'model': 'Random Forest', 'accuracy': accuracy}\n",
    "# csv_logger.log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.448431425088884\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create an XGBoost regressor\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "# log = {'model': 'XGBoost', 'accuracy': mse}\n",
    "# csv_logger.log(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# split into x and y where y is 'Group' \n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# log = {'model': 'Gradient Boost', 'accuracy': accuracy}\n",
    "# csv_logger.log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\Ananya\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660, 20)\n",
      "(660, 1)\n"
     ]
    }
   ],
   "source": [
    "# shape of x and y\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(20,)),\n",
    "    tf.keras.layers.Dense(16, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a test dataset for prediction (x_test)\n",
    "# Make sure that x_test has the same number of features as your training data (20 in this case)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# 'predictions' will contain the model's output, which are the class probabilities\n",
    "# You can choose the class with the highest probability as the predicted class\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "\n",
    "# 'predicted_classes' will contain the predicted class labels\n",
    "\n",
    "# If you have a mapping of class labels, you can map the labels back to their original values\n",
    "# For example, if 'final_dx_categorized' had labels like 0, 1, 2, etc.\n",
    "# and you have a mapping like {0: 'ClassA', 1: 'ClassB', 2: 'ClassC', ...}\n",
    "# you can do something like this to get the class labels:\n",
    "# predicted_class_labels = [your_mapping[class_idx] for class_idx in predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
